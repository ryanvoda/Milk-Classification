{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20d0b8d",
   "metadata": {},
   "source": [
    "# Milk Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a787b9",
   "metadata": {},
   "source": [
    "Import all packages, prepare our dataframe using kaggle dataset from https://www.kaggle.com/datasets/cpluzshrijayan/milkquality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a563294",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Temprature</th>\n",
       "      <th>Taste</th>\n",
       "      <th>Odor</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>253</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>246</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.5</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>255</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pH  Temprature  Taste  Odor  Fat   Turbidity  Colour   Grade\n",
       "0  6.6          35      1     0     1          0     254    high\n",
       "1  6.6          36      0     1     0          1     253    high\n",
       "2  8.5          70      1     1     1          1     246     low\n",
       "3  9.5          34      1     1     0          1     255     low\n",
       "4  6.6          37      0     0     0          0     255  medium"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import chi2, SelectKBest,SelectPercentile, f_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\ryvo1\\Downloads\\milknew.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86daf42",
   "metadata": {},
   "source": [
    "Now, check for null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1223310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1059 entries, 0 to 1058\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   pH          1059 non-null   float64\n",
      " 1   Temprature  1059 non-null   int64  \n",
      " 2   Taste       1059 non-null   int64  \n",
      " 3   Odor        1059 non-null   int64  \n",
      " 4   Fat         1059 non-null   int64  \n",
      " 5   Turbidity   1059 non-null   int64  \n",
      " 6   Colour      1059 non-null   int64  \n",
      " 7   Grade       1059 non-null   object \n",
      "dtypes: float64(1), int64(6), object(1)\n",
      "memory usage: 66.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6658440e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05996e",
   "metadata": {},
   "source": [
    "Therefore, df does not contain any null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35ae5de",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c684f88",
   "metadata": {},
   "source": [
    "We want to make a prediction model for the variable 'Grade', so we isolate it as our y variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ab088a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       429\n",
       "medium    374\n",
       "high      256\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.drop(columns='Grade')\n",
    "y = df['Grade']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36537104",
   "metadata": {},
   "source": [
    "Since we have an imbalance, we'll use SMOTE to randomly increase minority classes (medium and high, in this case), so we don't experience oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c6c573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "high      429\n",
       "low       429\n",
       "medium    429\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bettersample = SMOTE(random_state=0)\n",
    "x, y = bettersample.fit_resample(x,y)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498ebd1",
   "metadata": {},
   "source": [
    "Now, we just normalize our values, and perform our train/test split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91dbc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e27c427",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ad42f0",
   "metadata": {},
   "source": [
    "Models often perform better when only using a few key variables, which we will see if we can find."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49987e0",
   "metadata": {},
   "source": [
    "Let's look for variables which are significant in predicting milk grade:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c618e81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pH</th>\n",
       "      <th>Temprature</th>\n",
       "      <th>Taste</th>\n",
       "      <th>Odor</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Colour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.244684</td>\n",
       "      <td>-0.064053</td>\n",
       "      <td>-0.081331</td>\n",
       "      <td>-0.093429</td>\n",
       "      <td>0.048384</td>\n",
       "      <td>-0.164565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temprature</th>\n",
       "      <td>0.244684</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.109792</td>\n",
       "      <td>-0.048870</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.185106</td>\n",
       "      <td>-0.008511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taste</th>\n",
       "      <td>-0.064053</td>\n",
       "      <td>-0.109792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.324149</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>-0.082654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Odor</th>\n",
       "      <td>-0.081331</td>\n",
       "      <td>-0.048870</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314505</td>\n",
       "      <td>0.457935</td>\n",
       "      <td>-0.039361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fat</th>\n",
       "      <td>-0.093429</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.324149</td>\n",
       "      <td>0.314505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329264</td>\n",
       "      <td>0.114151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turbidity</th>\n",
       "      <td>0.048384</td>\n",
       "      <td>0.185106</td>\n",
       "      <td>0.055755</td>\n",
       "      <td>0.457935</td>\n",
       "      <td>0.329264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colour</th>\n",
       "      <td>-0.164565</td>\n",
       "      <td>-0.008511</td>\n",
       "      <td>-0.082654</td>\n",
       "      <td>-0.039361</td>\n",
       "      <td>0.114151</td>\n",
       "      <td>0.136436</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pH  Temprature     Taste      Odor      Fat   Turbidity  \\\n",
       "pH          1.000000    0.244684 -0.064053 -0.081331 -0.093429   0.048384   \n",
       "Temprature  0.244684    1.000000 -0.109792 -0.048870  0.024073   0.185106   \n",
       "Taste      -0.064053   -0.109792  1.000000  0.017582  0.324149   0.055755   \n",
       "Odor       -0.081331   -0.048870  0.017582  1.000000  0.314505   0.457935   \n",
       "Fat        -0.093429    0.024073  0.324149  0.314505  1.000000   0.329264   \n",
       "Turbidity   0.048384    0.185106  0.055755  0.457935  0.329264   1.000000   \n",
       "Colour     -0.164565   -0.008511 -0.082654 -0.039361  0.114151   0.136436   \n",
       "\n",
       "              Colour  \n",
       "pH         -0.164565  \n",
       "Temprature -0.008511  \n",
       "Taste      -0.082654  \n",
       "Odor       -0.039361  \n",
       "Fat         0.114151  \n",
       "Turbidity   0.136436  \n",
       "Colour      1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0681587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = df.corr()\n",
    "sns.heatmap(corr[(corr >= 0.3) | (corr <= -0.3)], \n",
    "            cmap='viridis', annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e384e85",
   "metadata": {},
   "source": [
    "Now we have an idea of which variables might be useful, but let's perform multiple tests and cross-validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5556ccfb",
   "metadata": {},
   "source": [
    "#### Test 1: Chi-Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e02c56",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.chi2.html#sklearn.feature_selection.chi2\n",
    "\n",
    "\"Recall that the chi-square test measures dependence between stochastic variables, so using this function 'weeds out' the features that are the most likely to be independent of class and therefore irrelevant for classification.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bab7a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turbidity</td>\n",
       "      <td>176.612245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Odor</td>\n",
       "      <td>143.136134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fat</td>\n",
       "      <td>114.145695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temprature</td>\n",
       "      <td>53.486398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taste</td>\n",
       "      <td>22.388350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colour</td>\n",
       "      <td>11.012380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pH</td>\n",
       "      <td>0.102586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features      scores\n",
       "5   Turbidity  176.612245\n",
       "3        Odor  143.136134\n",
       "4        Fat   114.145695\n",
       "1  Temprature   53.486398\n",
       "2       Taste   22.388350\n",
       "6      Colour   11.012380\n",
       "0          pH    0.102586"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "chi_best_col = SelectKBest(chi2,k='all')\n",
    "kbest = chi_best_col.fit_transform(x,y)\n",
    "pd.DataFrame(list(zip(df.drop(columns='Grade').columns,chi_best_col.scores_)),columns=['features','scores']).sort_values(by='scores',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad179ff9",
   "metadata": {},
   "source": [
    "So this test supports the removal of 'Colour', 'Taste', 'pH' from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f01b1a5",
   "metadata": {},
   "source": [
    "#### Test 2: Anova"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a12e1",
   "metadata": {},
   "source": [
    "In statistics, an ANOVA is used to determine whether there is a statistically significant difference between the means of three or more independent groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20d9d7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fat</td>\n",
       "      <td>274.612533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Turbidity</td>\n",
       "      <td>239.518365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Temprature</td>\n",
       "      <td>218.876159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Odor</td>\n",
       "      <td>167.424755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Colour</td>\n",
       "      <td>56.358174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Taste</td>\n",
       "      <td>26.440420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pH</td>\n",
       "      <td>0.751890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features      scores\n",
       "4        Fat   274.612533\n",
       "5   Turbidity  239.518365\n",
       "1  Temprature  218.876159\n",
       "3        Odor  167.424755\n",
       "6      Colour   56.358174\n",
       "2       Taste   26.440420\n",
       "0          pH    0.751890"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "f_best_col = SelectKBest(f_classif,k='all')\n",
    "kbest1 = f_best_col.fit_transform(x,y)\n",
    "pd.DataFrame(list(zip(df.drop(columns='Grade'),f_best_col.scores_)),columns=['features','scores']).sort_values(by='scores',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2a80b",
   "metadata": {},
   "source": [
    "So this test supports the removal of 'Colour', 'Taste', 'pH' from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639d730f",
   "metadata": {},
   "source": [
    "#### Test 3: Variance Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f42255",
   "metadata": {},
   "source": [
    "To increse the score of the model we need a dataset that has high variance, so it will be good if we can select the features in the dataset which has variance more than a fixed threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0abbec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns 'Grade' column into numerical representations, since this function works with numbers.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['Grade'] = encoder.fit_transform(df['Grade'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8184106d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False, False,  True, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "v = VarianceThreshold(threshold=1)\n",
    "v.fit_transform(df)\n",
    "v.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2482b58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pH', 'Temprature', 'Taste', 'Odor', 'Fat ', 'Turbidity', 'Colour',\n",
       "       'Grade'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48725f1",
   "metadata": {},
   "source": [
    "So this test supports the removal of 'pH', 'Temprature', 'Colour' from our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff619cf",
   "metadata": {},
   "source": [
    "##### Therefore, through cross-validation of these tests, we will try making a model with parameters 'Temprature', 'Odor', 'Fat ', 'Turbidity', 'Taste'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cce65642",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df[['Temprature', 'Odor', 'Fat ', 'Turbidity', 'Taste']]\n",
    "y1 = df['Grade']\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1,y1,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbaaf1f",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57c33e9",
   "metadata": {},
   "source": [
    "Let's find which model provides the highest accuracy prediction, using: 1. our set of \"optimized\" variables, and 2. our set of all variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763eaaea",
   "metadata": {},
   "source": [
    "#### Model 1: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b10af508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98449612 1.         1.         1.         0.9922179 ]\n",
      "Average Score (Old set): 0.9953428045727385\n"
     ]
    }
   ],
   "source": [
    "# Runs DecisionTreeClassifier on our old split:\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x_train,y_train)\n",
    "y_pred = dtc.predict(x_test)\n",
    "\n",
    "# Tests model's performance on cv=5 number of folds (to ensure it's working in general, not just on one section)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cross_validation_scores = cross_val_score(dtc,x,y,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (Old set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85dbdd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9009434  0.91037736 0.90566038 0.89622642 0.88625592]\n",
      "Average Score (New set): 0.8998926942680855\n"
     ]
    }
   ],
   "source": [
    "# Runs DecisionTreeClassifier on our new train/test split:\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(x1_train,y1_train)\n",
    "y1_pred = dtc.predict(x1_test)\n",
    "cross_validation_scores = cross_val_score(dtc,x1,y1,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (New set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10109c93",
   "metadata": {},
   "source": [
    "#### Model 2: SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ce87958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82170543 0.77131783 0.84824903 0.77821012 0.80155642]\n",
      "Average Score (Old set): 0.8042077640032577\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train, y_train)\n",
    "y_pred = svm_model_linear.predict(x_test)\n",
    "  \n",
    "cross_validation_scores = cross_val_score(svm_model_linear,x,y,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (Old set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21f88ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74528302 0.70754717 0.75       0.69811321 0.71090047]\n",
      "Average Score (New set): 0.7223687740320128\n"
     ]
    }
   ],
   "source": [
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x1_train, y1_train)\n",
    "y1_pred = svm_model_linear.predict(x1_test)\n",
    "  \n",
    "cross_validation_scores = cross_val_score(svm_model_linear,x1,y1,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (New set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d883870",
   "metadata": {},
   "source": [
    "#### Model 3: K-Nearest-Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3f14e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99612403 1.         0.98832685 0.99610895 0.9844358 ]\n",
      "Average Score (Old set): 0.9929991252676983\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(x_train, y_train)\n",
    "\n",
    "cross_validation_scores = cross_val_score(knn,x,y,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (Old set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fbd1ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91037736 0.91037736 0.90566038 0.9009434  0.86255924]\n",
      "Average Score (New set): 0.8979835464544397\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(x1_train, y1_train)\n",
    "\n",
    "cross_validation_scores = cross_val_score(knn,x1,y1,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (New set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb7cca",
   "metadata": {},
   "source": [
    "#### Model 4: Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a15e32",
   "metadata": {},
   "source": [
    "(Assumes independence between the variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63c2e2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8372093  0.91472868 0.90272374 0.92996109 0.87159533]\n",
      "Average Score (Old set): 0.8912436280276296\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB().fit(x_train, y_train)\n",
    "gnb_predictions = gnb.predict(x_test)\n",
    "  \n",
    "cross_validation_scores = cross_val_score(gnb,x,y,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (Old set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e27fd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58962264 0.63207547 0.74056604 0.60377358 0.67772512]\n",
      "Average Score (New set): 0.6487525708664938\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB().fit(x1_train, y1_train)\n",
    "gnb_predictions = gnb.predict(x1_test)\n",
    "  \n",
    "cross_validation_scores = cross_val_score(gnb,x1,y1,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (New set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8a02c0",
   "metadata": {},
   "source": [
    "#### Model 5: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62ca4f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86821705 0.84108527 0.87937743 0.83657588 0.85992218]\n",
      "0.8570355623925436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr = LogisticRegression()\n",
    "lgr.fit(x_train, y_train)\n",
    "y_pred = lgr.predict(x_test)\n",
    "\n",
    "cvs = cross_val_score(lgr,x,y,cv=5)\n",
    "print(cvs)\n",
    "print(cvs.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ff2531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryvo1\\anaconda3\\envs\\PIC16B\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ryvo1\\anaconda3\\envs\\PIC16B\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ryvo1\\anaconda3\\envs\\PIC16B\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ryvo1\\anaconda3\\envs\\PIC16B\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ryvo1\\anaconda3\\envs\\PIC16B\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.73584906 0.73584906 0.75471698 0.71698113 0.73933649]\n",
      "0.7365465438612179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryvo1\\anaconda3\\envs\\PIC16B\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lgr = LogisticRegression()\n",
    "lgr.fit(x1_train, y1_train)\n",
    "y_pred = lgr.predict(x1_test)\n",
    "\n",
    "cvs = cross_val_score(lgr,x1,y1,cv=5)\n",
    "print(cvs)\n",
    "print(cvs.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcfc1ee",
   "metadata": {},
   "source": [
    "#### Model 6: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3dc99e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99224806 1.         1.         1.         0.9922179 ]\n",
      "Average Score (Old set): 0.9968931921696378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "\n",
    "cross_validation_scores = cross_val_score(rfc,x,y,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (Old set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "beb3fd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89622642 0.91037736 0.90566038 0.89622642 0.8957346 ]\n",
      "Average Score (New set): 0.9008450326388268\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x1_train,y1_train)\n",
    "y1_pred = rfc.predict(x1_test)\n",
    "\n",
    "cross_validation_scores = cross_val_score(rfc,x1,y1,cv=5)\n",
    "print(cross_validation_scores)\n",
    "print(\"Average Score (New set):\", cross_validation_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca81bfb",
   "metadata": {},
   "source": [
    "The best score comes from our Random Forest Classifier model. The original set of variables provided better scores for all six models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62af98f1",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26a02b5",
   "metadata": {},
   "source": [
    "To ensure we are actually getting the best possible scores from our models, we will conduct hyperparameter tuning. \n",
    "\n",
    "This will show us if our set of all variables make for properly tuned hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f1aa5fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(max_depth=9),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': range(1, 10)})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict = {\n",
    "    \"criterion\":['gini','entropy'],\n",
    "    \"max_depth\":range(1,10)\n",
    "}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(rfc,param_grid=param_dict,cv=5)\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c27562e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini', 'max_depth': 6}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d690ff6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990291262135923"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aaab6e",
   "metadata": {},
   "source": [
    "Then, we have a highest accuracy of 99.9% via hyperparameter tuning. Applying these parameters to our current RandomForestClassifier gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "685dde90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.99      0.99      0.99        93\n",
      "         low       1.00      0.98      0.99        87\n",
      "      medium       0.97      1.00      0.99        78\n",
      "\n",
      "    accuracy                           0.99       258\n",
      "   macro avg       0.99      0.99      0.99       258\n",
      "weighted avg       0.99      0.99      0.99       258\n",
      "\n",
      "[0.99224806 1.         1.         1.         0.9922179 ]\n",
      "0.9968931921696378\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(criterion='gini',max_depth=6)\n",
    "rfc.fit(x_train,y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "\n",
    "cvsr = cross_val_score(rfc,x,y,cv=5)\n",
    "\n",
    "print(classification_report(y_test,yr_pred))\n",
    "\n",
    "print(cvsr)\n",
    "print(cvsr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad2a567",
   "metadata": {},
   "source": [
    "As we can see, applying the best parameters provides a similarly strong precision score, and since our recall and f1-scores aren't too disparate, we have conclusively created a very strong model to predict milk grade using RandomForestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0c6b49",
   "metadata": {},
   "source": [
    "# Summary and comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90de65aa",
   "metadata": {},
   "source": [
    "In this project, I have:\n",
    "\n",
    "- Imported a dataset of milk attributes and grade from https://www.kaggle.com/datasets/cpluzshrijayan/milkquality and converted it to a dataframe\n",
    "- Prepared the data to perform a train/test split\n",
    "- Cross-validated feature selection tests to find the strongest predicting features of milk grade\n",
    "- Ran the most optimal possible sets of data through several appropriate ML models\n",
    "- Conducted Hyperparameter tuning to ensure the selected features were indeed optimal\n",
    "- Ended up with an accurate predictor of milk grade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c195584",
   "metadata": {},
   "source": [
    "This project was unique in that all of my models performed better when using all of the possible variables as hyperparameters, and the accuracy was higher than I'd usually expect. I'd chalk this up to the dataset, as similar projects of mine (such as this one: https://github.com/ryanvoda/Penguins-Project/blob/main/PenguinProjectWalkthrough.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B] *",
   "language": "python",
   "name": "conda-env-PIC16B-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
